# Погружение и взаимодействие с брокером сообщений Kafka

## Ключевые понятия kafka

!!! note ""

    | Элемент                | Описание                                                                   | 
    | ---------------------- | -------------------------------------------------------------------------- |
    | `Брокер [broker]`      | Узел кластера Kafka, который выполняет различные функции: управление топиками, хранение чекпоинтов (комитов), координация групп и т. д.                                                                  |        
    | `Консьюмер [consumer]` | Клиент Kafka, основная задача которого – читать сообщения из топиков       |  
    | `Топик [topic]`        | Краспределённый файл (лог), разбитый на секции (партиции)                  |   
    | `Партиция [partition]` | Секция (шард) топика                                                       |   
    | `Группа [group]`       | Именованный набор консьюмеров, объединённых для совместного чтения топиков |   

## FAQ по Kafka

!!! note ""

    Полезная статья [на Habr](https://habr.com/ru/articles/916726/) 

    1. **Что вообще делает Kafka?**
    Kafka — это как лента событий внутри системы. Один сервис что то делает — другой на это реагирует. Всё пишется, всё хранится, всё можно перечитать. Это как централизованный «журнал жизни» твоей системы.

    2. Кто такие продюсеры (producers)?
    Это те, кто отправляет события в Kafka. Например, бекенд сервиса авторизации/регистрации шлёт user_logged_in, магазин шлёт order_created. Это просто отправка данных в нужную “тему(topic)”.

    3. **Кто такие потребители (consumers)?**
    Это те, кто читает события из Kafka. Причём читать могут сколько угодно разных сервисов(consumers), независимо друг от друга. Один пишет — трое читают, и все по своему.

    4. **Что такое тема (topic)?**
    Это канал событий. Например: user-events, payments, logs. Все события по одной теме — в одном месте.

    5. **Что такое partition?**
    Тема делится на разделы (partition'ы), чтобы можно было:
    параллельно обрабатывать данные,
    распределять нагрузку,
    масштабироваться.
    Kafka пишет события в партиции, и каждый consumer читает конкретные разделы.

    6. **А offset — это что?**
    Offset — это позиция сообщения внутри партиции. Каждый consumer запоминает, на каком offset он остановился. Потом может продолжить или перечитать с нужного места.

    7. **Можно ли перемотать и перечитать события?**
    Да! Это и есть одна из главных фич Kafka. Consumer может читать:
    с самого начала (earliest)
    только новое (latest)
    с конкретного offset

    8. **Что такое брокер (broker)?**
    Это просто сервер на котором установлена Kafka, который хранит и обрабатывает события. Kafka может работать на одном брокере, но в реальных системах используется кластер из нескольких брокеров на каждом из них установлен экземпляр кафки.

    9. **А кластер (cluster) зачем?**
    Чтобы было надёжно и масштабируемо. Один брокер упал — другие продолжают работать. Kafka раскидывает данные по брокерам, всё живёт в распределённой среде.

    10. **Kafka удаляет сообщения сразу после чтения?**
    Нет! Kafka хранит их столько, сколько ты скажешь. По времени или по размеру. Можно читать одно и то же сообщение хоть сто раз.

    11. **Что такое потоковая обработка (stream processing)?**
    Это когда события обрабатываются сразу, в момент поступления. Без задержек, без батчей. Kafka может работать с Kafka Streams или ksqlDB — ты можешь фильтровать, агрегировать, соединять события прямо в потоке. Kafka Streams — это Java only. Но ты можешь писать обычных consumer'ов на Go, Python, Node.js и т.д. А если хочешь стриминг без кода — есть ksqlDB с SQL запросами.
